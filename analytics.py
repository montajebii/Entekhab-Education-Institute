import pandas as pd
import numpy as np
from datetime import datetime, timedelta
from typing import List, Dict, Any, Optional
from config import *
from utils import convert_to_jalali, format_duration

class TaskAnalytics:
    def __init__(self, tasks_data: List[Dict[str, Any]]):
        self.df = pd.DataFrame(tasks_data)
        self._prepare_data()
    
    def _prepare_data(self) -> None:
        """Ø¢Ù…Ø§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø¨Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„"""
        # ØªØ¨Ø¯ÛŒÙ„ ØªØ§Ø±ÛŒØ®â€ŒÙ‡Ø§
        self.df['created_at'] = pd.to_datetime(self.df['created_at'])
        self.df['completed_at'] = pd.to_datetime(self.df['completed_at'])
        
        # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù…Ø¯Øª Ø²Ù…Ø§Ù† Ø§Ù†Ø¬Ø§Ù…
        self.df['duration'] = (self.df['completed_at'] - self.df['created_at']).dt.total_seconds() / 3600
        
        # Ù…Ø­Ø§Ø³Ø¨Ù‡ ØªØ§Ø®ÛŒØ±
        self.df['delay'] = (self.df['completed_at'] - self.df['created_at']).dt.total_seconds() / 3600 - self.df['estimated_duration']
    
    def get_basic_stats(self) -> Dict[str, Any]:
        """Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø¢Ù…Ø§Ø± Ù¾Ø§ÛŒÙ‡"""
        return {
            'total_tasks': len(self.df),
            'completed_tasks': len(self.df[self.df['status'] == 'completed']),
            'pending_tasks': len(self.df[self.df['status'] == 'pending']),
            'completion_rate': len(self.df[self.df['status'] == 'completed']) / len(self.df) if len(self.df) > 0 else 0,
            'avg_duration': self.df['duration'].mean(),
            'avg_delay': self.df['delay'].mean()
        }
    
    def get_priority_stats(self) -> Dict[str, Any]:
        """Ø¢Ù…Ø§Ø± Ù…Ø±Ø¨ÙˆØ· Ø¨Ù‡ Ø§ÙˆÙ„ÙˆÛŒØªâ€ŒÙ‡Ø§"""
        priority_counts = self.df['priority'].value_counts()
        priority_completion = self.df[self.df['status'] == 'completed']['priority'].value_counts()
        
        return {
            'distribution': priority_counts.to_dict(),
            'completion_by_priority': priority_completion.to_dict(),
            'completion_rate_by_priority': (priority_completion / priority_counts).to_dict()
        }
    
    def get_user_stats(self) -> Dict[str, Any]:
        """Ø¢Ù…Ø§Ø± Ù…Ø±Ø¨ÙˆØ· Ø¨Ù‡ Ú©Ø§Ø±Ø¨Ø±Ø§Ù†"""
        user_stats = self.df.groupby('assignee').agg({
            'id': 'count',
            'duration': 'mean',
            'delay': 'mean'
        }).rename(columns={
            'id': 'total_tasks',
            'duration': 'avg_duration',
            'delay': 'avg_delay'
        })
        
        return user_stats.to_dict('index')
    
    def get_trend_analysis(self, days: int = 30) -> Dict[str, Any]:
        """ØªØ­Ù„ÛŒÙ„ Ø±ÙˆÙ†Ø¯ Ø¯Ø± Ø¨Ø§Ø²Ù‡ Ø²Ù…Ø§Ù†ÛŒ Ù…Ø´Ø®Øµ"""
        end_date = datetime.now()
        start_date = end_date - timedelta(days=days)
        
        mask = (self.df['created_at'] >= start_date) & (self.df['created_at'] <= end_date)
        period_df = self.df[mask]
        
        daily_stats = period_df.groupby(period_df['created_at'].dt.date).agg({
            'id': 'count',
            'duration': 'mean',
            'delay': 'mean'
        }).rename(columns={
            'id': 'tasks_count',
            'duration': 'avg_duration',
            'delay': 'avg_delay'
        })
        
        return daily_stats.to_dict('index')
    
    def get_performance_metrics(self) -> Dict[str, Any]:
        """Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø´Ø§Ø®Øµâ€ŒÙ‡Ø§ÛŒ Ø¹Ù…Ù„Ú©Ø±Ø¯"""
        # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù†Ø±Ø® ØªÚ©Ù…ÛŒÙ„ Ø¨Ù‡ Ù…ÙˆÙ‚Ø¹
        on_time_completion = len(self.df[self.df['delay'] <= 0])
        on_time_rate = on_time_completion / len(self.df) if len(self.df) > 0 else 0
        
        # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Ø²Ù…Ø§Ù† ØªØ§Ø®ÛŒØ±
        avg_delay = self.df['delay'].mean()
        
        # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù†Ø±Ø® ØªÚ©Ù…ÛŒÙ„ ÙˆØ¸Ø§ÛŒÙ Ø¨Ø§ Ø§ÙˆÙ„ÙˆÛŒØª Ø¨Ø§Ù„Ø§
        high_priority_tasks = self.df[self.df['priority'] == 'high']
        high_priority_completion = len(high_priority_tasks[high_priority_tasks['status'] == 'completed'])
        high_priority_rate = high_priority_completion / len(high_priority_tasks) if len(high_priority_tasks) > 0 else 0
        
        return {
            'on_time_completion_rate': on_time_rate,
            'average_delay': avg_delay,
            'high_priority_completion_rate': high_priority_rate
        }
    
    def get_efficiency_analysis(self) -> Dict[str, Any]:
        """ØªØ­Ù„ÛŒÙ„ Ú©Ø§Ø±Ø§ÛŒÛŒ"""
        # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù†Ø³Ø¨Øª Ø²Ù…Ø§Ù† ÙˆØ§Ù‚Ø¹ÛŒ Ø¨Ù‡ Ø²Ù…Ø§Ù† ØªØ®Ù…ÛŒÙ†ÛŒ
        self.df['efficiency_ratio'] = self.df['estimated_duration'] / self.df['duration']
        
        # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Ú©Ø§Ø±Ø§ÛŒÛŒ
        avg_efficiency = self.df['efficiency_ratio'].mean()
        
        # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ú©Ø§Ø±Ø§ÛŒÛŒ Ø¨Ù‡ ØªÙÚ©ÛŒÚ© Ø§ÙˆÙ„ÙˆÛŒØª
        efficiency_by_priority = self.df.groupby('priority')['efficiency_ratio'].mean()
        
        return {
            'average_efficiency': avg_efficiency,
            'efficiency_by_priority': efficiency_by_priority.to_dict()
        }
    
    def generate_report(self) -> Dict[str, Any]:
        """ØªÙˆÙ„ÛŒØ¯ Ú¯Ø²Ø§Ø±Ø´ Ø¬Ø§Ù…Ø¹"""
        return {
            'basic_stats': self.get_basic_stats(),
            'priority_stats': self.get_priority_stats(),
            'user_stats': self.get_user_stats(),
            'trend_analysis': self.get_trend_analysis(),
            'performance_metrics': self.get_performance_metrics(),
            'efficiency_analysis': self.get_efficiency_analysis()
        }
    
    def format_report(self, report: Dict[str, Any]) -> str:
        """ÙØ±Ù…Øªâ€ŒØ¨Ù†Ø¯ÛŒ Ú¯Ø²Ø§Ø±Ø´ Ø¨Ø±Ø§ÛŒ Ù†Ù…Ø§ÛŒØ´"""
        basic_stats = report['basic_stats']
        priority_stats = report['priority_stats']
        performance_metrics = report['performance_metrics']
        
        return f"""
ğŸ“Š Ú¯Ø²Ø§Ø±Ø´ Ø¹Ù…Ù„Ú©Ø±Ø¯ Ø³ÛŒØ³ØªÙ… Ù…Ø¯ÛŒØ±ÛŒØª ÙˆØ¸Ø§ÛŒÙ

ğŸ“ˆ Ø¢Ù…Ø§Ø± Ú©Ù„ÛŒ:
â€¢ ØªØ¹Ø¯Ø§Ø¯ Ú©Ù„ ÙˆØ¸Ø§ÛŒÙ: {basic_stats['total_tasks']}
â€¢ ÙˆØ¸Ø§ÛŒÙ ØªÚ©Ù…ÛŒÙ„ Ø´Ø¯Ù‡: {basic_stats['completed_tasks']}
â€¢ Ù†Ø±Ø® ØªÚ©Ù…ÛŒÙ„: {basic_stats['completion_rate']:.1%}
â€¢ Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Ø²Ù…Ø§Ù† Ø§Ù†Ø¬Ø§Ù…: {format_duration(basic_stats['avg_duration'] * 3600)}
â€¢ Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† ØªØ§Ø®ÛŒØ±: {format_duration(basic_stats['avg_delay'] * 3600)}

âš¡ Ø¢Ù…Ø§Ø± Ø§ÙˆÙ„ÙˆÛŒØªâ€ŒÙ‡Ø§:
â€¢ ØªÙˆØ²ÛŒØ¹ Ø§ÙˆÙ„ÙˆÛŒØªâ€ŒÙ‡Ø§: {', '.join(f'{k}: {v}' for k, v in priority_stats['distribution'].items())}
â€¢ Ù†Ø±Ø® ØªÚ©Ù…ÛŒÙ„ Ø¨Ù‡ ØªÙÚ©ÛŒÚ© Ø§ÙˆÙ„ÙˆÛŒØª: {', '.join(f'{k}: {v:.1%}' for k, v in priority_stats['completion_rate_by_priority'].items())}

ğŸ¯ Ø´Ø§Ø®Øµâ€ŒÙ‡Ø§ÛŒ Ø¹Ù…Ù„Ú©Ø±Ø¯:
â€¢ Ù†Ø±Ø® ØªÚ©Ù…ÛŒÙ„ Ø¨Ù‡ Ù…ÙˆÙ‚Ø¹: {performance_metrics['on_time_completion_rate']:.1%}
â€¢ Ù†Ø±Ø® ØªÚ©Ù…ÛŒÙ„ ÙˆØ¸Ø§ÛŒÙ Ø¨Ø§ Ø§ÙˆÙ„ÙˆÛŒØª Ø¨Ø§Ù„Ø§: {performance_metrics['high_priority_completion_rate']:.1%}
â€¢ Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† ØªØ§Ø®ÛŒØ±: {format_duration(performance_metrics['average_delay'] * 3600)}

ğŸ“… ØªØ§Ø±ÛŒØ® Ú¯Ø²Ø§Ø±Ø´: {convert_to_jalali(datetime.now())}
""" 